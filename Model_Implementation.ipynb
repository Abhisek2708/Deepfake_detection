{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf200849-0910-43c5-9315-195580b47767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee8caabf-6795-4cb9-9706-7047a0a22ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = \"E:\\\\Momenta_task\\\\LJSpeech-1.1\\\\wavs\"\n",
    "METADATA_PATH = \"E:\\\\Momenta_task\\\\LJSpeech-1.1\\\\metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1106d281-baf5-4d80-9b48-1819b94035d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(METADATA_PATH, sep=\"|\", header=None, \n",
    "                      names=[\"ID\", \"Transcript\", \"Normalized\"], \n",
    "                      usecols=[\"ID\"])\n",
    "metadata['Label'] = np.random.randint(0, 2, size=len(metadata))  # Replace with real labels\n",
    "\n",
    "train_df, temp_df = train_test_split(metadata, test_size=0.2, stratify=metadata['Label'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc78a873-df49-419d-b60e-050a6c0fde40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=16000, duration=4)  # Fixed duration\n",
    "        y = librosa.util.fix_length(y, size=64000)  # 4 seconds\n",
    "        \n",
    "        # MFCC with stable dimensions\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40, n_fft=512, hop_length=256)\n",
    "        mfcc = mfcc[:, :250]  # Fix time dimension\n",
    "        \n",
    "        # Normalize\n",
    "        mfcc = (mfcc - np.mean(mfcc)) / np.std(mfcc)\n",
    "        return torch.FloatTensor(mfcc.T)  # (250, 40)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {str(e)}\")\n",
    "        return torch.zeros((250, 40))  # Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4f33c03-dbb7-4c96-b708-0f77ec53b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, df, audio_dir):\n",
    "        self.df = df\n",
    "        self.audio_dir = audio_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_file = self.df.iloc[idx]['ID'] + '.wav'  # LJSpeech uses .wav\n",
    "        audio_path = os.path.join(self.audio_dir, audio_file)\n",
    "        features = extract_features(audio_path)\n",
    "        label = self.df.iloc[idx]['Label']\n",
    "        return features, torch.tensor(label)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    features, labels = zip(*batch)\n",
    "    return torch.stack(features), torch.stack(labels)\n",
    "\n",
    "# Initialize loaders\n",
    "train_loader = DataLoader(AudioDataset(train_df, AUDIO_DIR), \n",
    "                         batch_size=32, collate_fn=collate_fn, shuffle=True)\n",
    "val_loader = DataLoader(AudioDataset(val_df, AUDIO_DIR), batch_size=32, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(AudioDataset(test_df, AUDIO_DIR), batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0298fab3-981b-45c6-b4cc-cb9502cc18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGLSTM(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Stable CNN for fixed input size\n",
    "        self.cnn = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(40, 64, kernel_size=5),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(4),\n",
    "            torch.nn.Conv1d(64, 128, kernel_size=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2)\n",
    "        )\n",
    "        \n",
    "        # LSTM with attention\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size=128,\n",
    "            hidden_size=64,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.fc = torch.nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, time, features)\n",
    "        x = x.permute(0, 2, 1)  # (batch, features, time)\n",
    "        \n",
    "        # CNN processing\n",
    "        x = self.cnn(x)\n",
    "        x = x.permute(0, 2, 1)  # (batch, time, features)\n",
    "        \n",
    "        # LSTM processing\n",
    "        out, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # Use final hidden state\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fe5c013-1038-4cf7-af32-506f28ad9870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 328/328 [05:16<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.6939 | Val F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 328/328 [01:54<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 0.6931 | Val F1: 0.3518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 328/328 [01:54<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 0.6930 | Val F1: 0.6403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 328/328 [01:54<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 0.6926 | Val F1: 0.6372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 328/328 [01:55<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Loss: 0.6925 | Val F1: 0.4608\n"
     ]
    }
   ],
   "source": [
    "model = VGGLSTM()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# %% [8] Training Loop (CPU-optimized)\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.long())  # Fix here\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            val_preds.extend(preds.numpy())\n",
    "            val_labels.extend(labels.numpy())  # labels already converted in dataset\n",
    "    \n",
    "    val_f1 = f1_score(val_labels, val_preds)\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Val F1: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8310532b-518e-4334-9a7a-bdb214c89fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation:\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    print(classification_report(all_labels, all_preds))\n",
    "    print(f\"F1 Score: {f1_score(all_labels, all_preds):.4f}\")\n",
    "\n",
    "print(\"Test Set Evaluation:\")\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2418e1a9-6ce7-46ef-a99d-700e5433ef09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
